import datetime, os, glob, hashlib, re
from pathlib import Path
from snakemake.exceptions import WorkflowError
from snakemake.logging import logger

configfile: "scripts/cluster/sc/yaml_files/single-seed-multiround-config.yaml"
# run these rules on the driver (not via Slurm)
localrules: snapshot_manifest

# -------- basics --------
PROJECT_ROOT = os.getcwd()
RUNS = os.path.join(PROJECT_ROOT, config.get("paths", {}).get("base_dir", "runs"))

RUN_ID = config["run"]["run_id"].format(date=datetime.datetime.now())
ROUNDS = list(range(config["run"]["rounds"]))
SLURM  = config["slurm_defaults"]

# -------- task resolution (dirs -> *.json files) --------
def _resolve_tasks(entries, root):
    resolved = []
    for e in entries:
        p = Path(e)
        abs_p = p if p.is_absolute() else Path(root) / p
        if abs_p.is_dir():
            files = sorted(str(x) for x in abs_p.glob("*.json"))
            if not files:
                raise WorkflowError(f"No *.json tasks found in directory: {abs_p}")
            resolved.extend(files)
        else:
            if abs_p.suffix != ".json":
                raise WorkflowError(f"Task entry is not a .json file or directory: {abs_p}")
            resolved.append(str(abs_p))
    return resolved

TRAIN = _resolve_tasks(config["tasks"]["train"], PROJECT_ROOT)
EVAL  = _resolve_tasks(config["tasks"]["eval"],  PROJECT_ROOT)

if not TRAIN:
    raise WorkflowError("tasks.train resolved to an empty list. Check your config paths.")
if not EVAL:
    raise WorkflowError("tasks.eval resolved to an empty list. Check your config paths.")

# -------- stable, safe IDs --------
def make_task_id(path: str) -> str:
    rel = os.path.relpath(path, PROJECT_ROOT)
    h = hashlib.sha1(rel.encode()).hexdigest()[:8]
    stem = Path(path).stem
    return f"{stem}-{h}"

TRAIN_IDS = [make_task_id(p) for p in TRAIN]
EVAL_IDS  = [make_task_id(p) for p in EVAL]
TRAIN_MAP = {tid: path for tid, path in zip(TRAIN_IDS, TRAIN)}
EVAL_MAP  = {eid: path for eid, path in zip(EVAL_IDS, EVAL)}

# -------- helpers for concrete paths --------
def run_root():         return os.path.join(RUNS, RUN_ID)
def rdir(r):            return os.path.join(run_root(), f"round_{r}")
def merged_path(r):     return os.path.join(rdir(r), "collect", "merged", "finetune_dataset.parquet")
def best_epoch(r):      return os.path.join(rdir(r), "train", "BEST_EPOCH.txt")
def ckpt_selected(r):   return os.path.join(rdir(r), "train", "checkpoints", "SELECTED")
def eval_summary(r):    return os.path.join(rdir(r), "eval", "summary", "metrics.json")

# -------- pattern strings (use ONE style: run_root()) --------
COLLECT_SUCCESS = os.path.join(run_root(), "round_{r}", "collect", "tasks", "{task_id}", "_SUCCESS")
COLLECT_LOG     = os.path.join(run_root(), "round_{r}", "collect", "tasks", "{task_id}", "collect.log")

MERGED_FILE     = os.path.join(run_root(), "round_{r}", "collect", "merged", "finetune_dataset.parquet")
MERGE_LOG       = os.path.join(run_root(), "round_{r}", "collect", "merge.log")

BEST_EPOCH_FILE = os.path.join(run_root(), "round_{r}", "train", "BEST_EPOCH.txt")
SELECTED_LINK   = os.path.join(run_root(), "round_{r}", "train", "checkpoints", "SELECTED")
TRAIN_LOG       = os.path.join(run_root(), "round_{r}", "train", "train.log")

EVAL_SUCCESS    = os.path.join(run_root(), "round_{r}", "eval", "tasks", "{task_id}", "_SUCCESS")
EVAL_LOG        = os.path.join(run_root(), "round_{r}", "eval", "tasks", "{task_id}", "eval.log")

EVAL_SUMMARY    = os.path.join(run_root(), "round_{r}", "eval", "summary", "metrics.json")
AGG_LOG         = os.path.join(run_root(), "round_{r}", "eval", "aggregate.log")

# ---------------- rules ----------------

rule all:
    input:
        os.path.join(run_root(), "manifest.snapshot.yaml"),
        *[merged_path(r) for r in ROUNDS],
        *[ckpt_selected(r) for r in ROUNDS],
        *[eval_summary(r) for r in ROUNDS]

rule snapshot_manifest:
    output:
        os.path.join(run_root(), "manifest.snapshot.yaml")
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname "{output}")"
        cp "scripts/cluster/sc/yaml_files/single-seed-multiround-config.yaml" "{output}"
        """

# ---- collect (fan-out) ----
safe_id_re = r"[A-Za-z0-9_-]+"

rule collect_task:
    input:
        os.path.join(run_root(), "manifest.snapshot.yaml")
    output:
        COLLECT_SUCCESS
    wildcard_constraints:
        r="|".join(map(str, ROUNDS)),
        task_id=safe_id_re
    params:
        task_path=lambda w: TRAIN_MAP[w.task_id]
    resources:
        time=SLURM["time"]["collect"], mem=SLURM["resources"]["collect"]["mem"],
        gpus=SLURM["resources"]["collect"]["gpus"], qos=SLURM["qos"],
        account=SLURM["account"], partition=SLURM.get("partition") or ""
    threads: SLURM["resources"]["collect"]["cpus"]
    log:
        COLLECT_LOG
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname "{output}")"
        echo "[stub] collect {params.task_path} (task_id={wildcards.task_id}) round {wildcards.r}" | tee "{log}"
        touch "{output}"
        """

# ---- merge (fan-in) ----
rule merge_dataset:
    input:
        lambda w: expand(COLLECT_SUCCESS, r=w.r, task_id=TRAIN_IDS)
    output:
        MERGED_FILE
    resources:
        time=SLURM["time"]["merge"], mem=SLURM["resources"]["merge"]["mem"],
        gpus=SLURM["resources"]["merge"]["gpus"], qos=SLURM["qos"],
        account=SLURM["account"], partition=SLURM.get("partition") or ""
    threads: SLURM["resources"]["merge"]["cpus"]
    log:
        MERGE_LOG
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname "{output}")"
        echo "[stub] merge" | tee "{log}"
        echo "DUMMY" > "{output}"
        """

# ---- train ----
rule train_model:
    input:
        lambda w: merged_path(int(w.r))
    output:
        BEST_EPOCH_FILE,
        SELECTED_LINK
    resources:
        time=SLURM["time"]["train"], mem=SLURM["resources"]["train"]["mem"],
        gpus=SLURM["resources"]["train"]["gpus"], qos=SLURM["qos"],
        account=SLURM["account"], partition=SLURM.get("partition") or ""
    threads: SLURM["resources"]["train"]["cpus"]
    log:
        TRAIN_LOG
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname "{output[0]}")"  # .../train
        mkdir -p "$(dirname "{output[1]}")"  # .../train/checkpoints
        echo "BEST_EPOCH=300" | tee "{log}"
        echo 300 > "{output[0]}"
        """

# ---- eval (fan-out) ----
rule eval_task:
    input:
        lambda w: ckpt_selected(int(w.r))
    output:
        EVAL_SUCCESS
    wildcard_constraints:
        r="|".join(map(str, ROUNDS)),
        task_id=safe_id_re
    params:
        task_path=lambda w: EVAL_MAP[w.task_id]
    resources:
        time=SLURM["time"]["eval"], mem=SLURM["resources"]["eval"]["mem"],
        gpus=SLURM["resources"]["eval"]["gpus"], qos=SLURM["qos"],
        account=SLURM["account"], partition=SLURM.get("partition") or ""
    threads: SLURM["resources"]["eval"]["cpus"]
    log:
        EVAL_LOG
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname "{output}")"
        echo "[stub] eval {params.task_path} (task_id={wildcards.task_id}) using {input}" | tee "{log}"
        touch "{output}"
        """

# ---- aggregate (fan-in) ----
rule aggregate_eval:
    input:
        lambda w: expand(EVAL_SUCCESS, r=w.r, task_id=EVAL_IDS)
    output:
        EVAL_SUMMARY
    resources:
        time=SLURM["time"]["aggregate"], mem=SLURM["resources"]["aggregate"]["mem"],
        gpus=SLURM["resources"]["aggregate"]["gpus"], qos=SLURM["qos"],
        account=SLURM["account"], partition=SLURM.get("partition") or ""
    threads: SLURM["resources"]["aggregate"]["cpus"]
    log:
        AGG_LOG
    shell:
        r"""
        set -euo pipefail
        mkdir -p "$(dirname "{output}")"
        echo '{{"status":"ok","round":{wildcards.r}}}' > "{output}"
        echo "[stub] aggregate" | tee "{log}"
        """
